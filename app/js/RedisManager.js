// Generated by CoffeeScript 1.7.1
(function() {
  var Errors, MAX_RANGES_SIZE, MAX_REDIS_REQUEST_LENGTH, MEGABYTES, ProjectHistoryRedisManager, RedisManager, Settings, async, crypto, historyKeys, keys, logHashErrors, logHashReadErrors, logger, metrics, minutes, rclient, _ref,
    __slice = [].slice;

  Settings = require('settings-sharelatex');

  rclient = require("redis-sharelatex").createClient(Settings.redis.documentupdater);

  logger = require('logger-sharelatex');

  metrics = require('./Metrics');

  Errors = require("./Errors");

  crypto = require("crypto");

  async = require("async");

  ProjectHistoryRedisManager = require("./ProjectHistoryRedisManager");

  MAX_REDIS_REQUEST_LENGTH = 5000;

  minutes = 60;

  logHashErrors = (_ref = Settings.documentupdater) != null ? _ref.logHashErrors : void 0;

  logHashReadErrors = logHashErrors != null ? logHashErrors.read : void 0;

  MEGABYTES = 1024 * 1024;

  MAX_RANGES_SIZE = 3 * MEGABYTES;

  keys = Settings.redis.documentupdater.key_schema;

  historyKeys = Settings.redis.history.key_schema;

  module.exports = RedisManager = {
    rclient: rclient,
    putDocInMemory: function(project_id, doc_id, docLines, version, ranges, pathname, projectHistoryId, _callback) {
      var callback, docHash, error, timer;
      timer = new metrics.Timer("redis.put-doc");
      callback = function(error) {
        timer.done();
        return _callback(error);
      };
      docLines = JSON.stringify(docLines);
      if (docLines.indexOf("\u0000") !== -1) {
        error = new Error("null bytes found in doc lines");
        logger.error({
          err: error,
          doc_id: doc_id,
          docLines: docLines
        }, error.message);
        return callback(error);
      }
      docHash = RedisManager._computeHash(docLines);
      logger.log({
        project_id: project_id,
        doc_id: doc_id,
        version: version,
        docHash: docHash,
        pathname: pathname,
        projectHistoryId: projectHistoryId
      }, "putting doc in redis");
      return RedisManager._serializeRanges(ranges, function(error, ranges) {
        var multi;
        if (error != null) {
          logger.error({
            err: error,
            doc_id: doc_id,
            project_id: project_id
          }, error.message);
          return callback(error);
        }
        multi = rclient.multi();
        multi.set(keys.docLines({
          doc_id: doc_id
        }), docLines);
        multi.set(keys.projectKey({
          doc_id: doc_id
        }), project_id);
        multi.set(keys.docVersion({
          doc_id: doc_id
        }), version);
        multi.set(keys.docHash({
          doc_id: doc_id
        }), docHash);
        if (ranges != null) {
          multi.set(keys.ranges({
            doc_id: doc_id
          }), ranges);
        } else {
          multi.del(keys.ranges({
            doc_id: doc_id
          }));
        }
        multi.set(keys.pathname({
          doc_id: doc_id
        }), pathname);
        multi.set(keys.projectHistoryId({
          doc_id: doc_id
        }), projectHistoryId);
        return multi.exec(function(error, result) {
          if (error != null) {
            return callback(error);
          }
          return rclient.sadd(keys.docsInProject({
            project_id: project_id
          }), doc_id, callback);
        });
      });
    },
    removeDocFromMemory: function(project_id, doc_id, _callback) {
      var callback, multi;
      logger.log({
        project_id: project_id,
        doc_id: doc_id
      }, "removing doc from redis");
      callback = function(err) {
        if (err != null) {
          logger.err({
            project_id: project_id,
            doc_id: doc_id,
            err: err
          }, "error removing doc from redis");
          return _callback(err);
        } else {
          logger.log({
            project_id: project_id,
            doc_id: doc_id
          }, "removed doc from redis");
          return _callback();
        }
      };
      multi = rclient.multi();
      multi.del(keys.docLines({
        doc_id: doc_id
      }));
      multi.del(keys.projectKey({
        doc_id: doc_id
      }));
      multi.del(keys.docVersion({
        doc_id: doc_id
      }));
      multi.del(keys.docHash({
        doc_id: doc_id
      }));
      multi.del(keys.ranges({
        doc_id: doc_id
      }));
      multi.del(keys.pathname({
        doc_id: doc_id
      }));
      multi.del(keys.projectHistoryId({
        doc_id: doc_id
      }));
      multi.del(keys.projectHistoryType({
        doc_id: doc_id
      }));
      multi.del(keys.unflushedTime({
        doc_id: doc_id
      }));
      multi.del(keys.lastUpdatedAt({
        doc_id: doc_id
      }));
      multi.del(keys.lastUpdatedBy({
        doc_id: doc_id
      }));
      return multi.exec(function(error) {
        if (error != null) {
          return callback(error);
        }
        multi = rclient.multi();
        multi.srem(keys.docsInProject({
          project_id: project_id
        }), doc_id);
        multi.del(keys.projectState({
          project_id: project_id
        }));
        return multi.exec(callback);
      });
    },
    checkOrSetProjectState: function(project_id, newState, callback) {
      var multi;
      if (callback == null) {
        callback = function(error, stateChanged) {};
      }
      multi = rclient.multi();
      multi.getset(keys.projectState({
        project_id: project_id
      }), newState);
      multi.expire(keys.projectState({
        project_id: project_id
      }), 30 * minutes);
      return multi.exec(function(error, response) {
        if (error != null) {
          return callback(error);
        }
        logger.log({
          project_id: project_id,
          newState: newState,
          oldState: response[0]
        }, "checking project state");
        return callback(null, response[0] !== newState);
      });
    },
    clearProjectState: function(project_id, callback) {
      if (callback == null) {
        callback = function(error) {};
      }
      return rclient.del(keys.projectState({
        project_id: project_id
      }), callback);
    },
    getDoc: function(project_id, doc_id, callback) {
      var multi, timer;
      if (callback == null) {
        callback = function(error, lines, version, ranges, pathname, projectHistoryId, unflushedTime) {};
      }
      timer = new metrics.Timer("redis.get-doc");
      multi = rclient.multi();
      multi.get(keys.docLines({
        doc_id: doc_id
      }));
      multi.get(keys.docVersion({
        doc_id: doc_id
      }));
      multi.get(keys.docHash({
        doc_id: doc_id
      }));
      multi.get(keys.projectKey({
        doc_id: doc_id
      }));
      multi.get(keys.ranges({
        doc_id: doc_id
      }));
      multi.get(keys.pathname({
        doc_id: doc_id
      }));
      multi.get(keys.projectHistoryId({
        doc_id: doc_id
      }));
      multi.get(keys.unflushedTime({
        doc_id: doc_id
      }));
      multi.get(keys.lastUpdatedAt({
        doc_id: doc_id
      }));
      multi.get(keys.lastUpdatedBy({
        doc_id: doc_id
      }));
      return multi.exec(function(error, _arg) {
        var computedHash, docLines, doc_project_id, e, lastUpdatedAt, lastUpdatedBy, pathname, projectHistoryId, ranges, storedHash, timeSpan, unflushedTime, version;
        docLines = _arg[0], version = _arg[1], storedHash = _arg[2], doc_project_id = _arg[3], ranges = _arg[4], pathname = _arg[5], projectHistoryId = _arg[6], unflushedTime = _arg[7], lastUpdatedAt = _arg[8], lastUpdatedBy = _arg[9];
        timeSpan = timer.done();
        if (error != null) {
          return callback(error);
        }
        if (timeSpan > MAX_REDIS_REQUEST_LENGTH) {
          error = new Error("redis getDoc exceeded timeout");
          return callback(error);
        }
        if ((docLines != null) && (storedHash != null)) {
          computedHash = RedisManager._computeHash(docLines);
          if (logHashReadErrors && computedHash !== storedHash) {
            logger.error({
              project_id: project_id,
              doc_id: doc_id,
              doc_project_id: doc_project_id,
              computedHash: computedHash,
              storedHash: storedHash,
              docLines: docLines
            }, "hash mismatch on retrieved document");
          }
        }
        try {
          docLines = JSON.parse(docLines);
          ranges = RedisManager._deserializeRanges(ranges);
        } catch (_error) {
          e = _error;
          return callback(e);
        }
        version = parseInt(version || 0, 10);
        if ((doc_project_id != null) && doc_project_id !== project_id) {
          logger.error({
            project_id: project_id,
            doc_id: doc_id,
            doc_project_id: doc_project_id
          }, "doc not in project");
          return callback(new Errors.NotFoundError("document not found"));
        }
        if (projectHistoryId != null) {
          projectHistoryId = parseInt(projectHistoryId);
        }
        if (docLines == null) {
          return callback(null, docLines, version, ranges, pathname, projectHistoryId, unflushedTime, lastUpdatedAt, lastUpdatedBy);
        }
        return rclient.sadd(keys.docsInProject({
          project_id: project_id
        }), doc_id, function(error, result) {
          if (error != null) {
            return callback(error);
          }
          if (result !== 0) {
            logger.error({
              project_id: project_id,
              doc_id: doc_id,
              doc_project_id: doc_project_id
            }, "doc missing from docsInProject set");
          }
          return callback(null, docLines, version, ranges, pathname, projectHistoryId, unflushedTime, lastUpdatedAt, lastUpdatedBy);
        });
      });
    },
    getDocVersion: function(doc_id, callback) {
      if (callback == null) {
        callback = function(error, version, projectHistoryType) {};
      }
      return rclient.mget(keys.docVersion({
        doc_id: doc_id
      }), keys.projectHistoryType({
        doc_id: doc_id
      }), function(error, result) {
        var projectHistoryType, version, _ref1;
        if (error != null) {
          return callback(error);
        }
        _ref1 = result || [], version = _ref1[0], projectHistoryType = _ref1[1];
        version = parseInt(version, 10);
        return callback(null, version, projectHistoryType);
      });
    },
    getDocLines: function(doc_id, callback) {
      if (callback == null) {
        callback = function(error, version) {};
      }
      return rclient.get(keys.docLines({
        doc_id: doc_id
      }), function(error, docLines) {
        if (error != null) {
          return callback(error);
        }
        return callback(null, docLines);
      });
    },
    getPreviousDocOps: function(doc_id, start, end, callback) {
      var timer;
      if (callback == null) {
        callback = function(error, jsonOps) {};
      }
      timer = new metrics.Timer("redis.get-prev-docops");
      return rclient.llen(keys.docOps({
        doc_id: doc_id
      }), function(error, length) {
        if (error != null) {
          return callback(error);
        }
        return rclient.get(keys.docVersion({
          doc_id: doc_id
        }), function(error, version) {
          var first_version_in_redis;
          if (error != null) {
            return callback(error);
          }
          version = parseInt(version, 10);
          first_version_in_redis = version - length;
          if (start < first_version_in_redis || end > version) {
            error = new Errors.OpRangeNotAvailableError("doc ops range is not loaded in redis");
            logger.warn({
              err: error,
              doc_id: doc_id,
              length: length,
              version: version,
              start: start,
              end: end
            }, "doc ops range is not loaded in redis");
            return callback(error);
          }
          start = start - first_version_in_redis;
          if (end > -1) {
            end = end - first_version_in_redis;
          }
          if (isNaN(start) || isNaN(end)) {
            error = new Error("inconsistent version or lengths");
            logger.error({
              err: error,
              doc_id: doc_id,
              length: length,
              version: version,
              start: start,
              end: end
            }, "inconsistent version or length");
            return callback(error);
          }
          return rclient.lrange(keys.docOps({
            doc_id: doc_id
          }), start, end, function(error, jsonOps) {
            var e, ops, timeSpan;
            if (error != null) {
              return callback(error);
            }
            try {
              ops = jsonOps.map(function(jsonOp) {
                return JSON.parse(jsonOp);
              });
            } catch (_error) {
              e = _error;
              return callback(e);
            }
            timeSpan = timer.done();
            if (timeSpan > MAX_REDIS_REQUEST_LENGTH) {
              error = new Error("redis getPreviousDocOps exceeded timeout");
              return callback(error);
            }
            return callback(null, ops);
          });
        });
      });
    },
    getHistoryType: function(doc_id, callback) {
      if (callback == null) {
        callback = function(error, projectHistoryType) {};
      }
      return rclient.get(keys.projectHistoryType({
        doc_id: doc_id
      }), function(error, projectHistoryType) {
        if (error != null) {
          return callback(error);
        }
        return callback(null, projectHistoryType);
      });
    },
    setHistoryType: function(doc_id, projectHistoryType, callback) {
      if (callback == null) {
        callback = function(error) {};
      }
      return rclient.set(keys.projectHistoryType({
        doc_id: doc_id
      }), projectHistoryType, callback);
    },
    DOC_OPS_TTL: 60 * minutes,
    DOC_OPS_MAX_LENGTH: 100,
    updateDocument: function(project_id, doc_id, docLines, newVersion, appliedOps, ranges, updateMeta, callback) {
      if (appliedOps == null) {
        appliedOps = [];
      }
      if (callback == null) {
        callback = function(error) {};
      }
      return RedisManager.getDocVersion(doc_id, function(error, currentVersion, projectHistoryType) {
        var jsonOps, newDocLines, newHash, op, opVersions, _i, _len;
        if (error != null) {
          return callback(error);
        }
        if (currentVersion + appliedOps.length !== newVersion) {
          error = new Error("Version mismatch. '" + doc_id + "' is corrupted.");
          logger.error({
            err: error,
            doc_id: doc_id,
            currentVersion: currentVersion,
            newVersion: newVersion,
            opsLength: appliedOps.length
          }, "version mismatch");
          return callback(error);
        }
        jsonOps = appliedOps.map(function(op) {
          return JSON.stringify(op);
        });
        for (_i = 0, _len = jsonOps.length; _i < _len; _i++) {
          op = jsonOps[_i];
          if (op.indexOf("\u0000") !== -1) {
            error = new Error("null bytes found in jsonOps");
            logger.error({
              err: error,
              doc_id: doc_id,
              jsonOps: jsonOps
            }, error.message);
            return callback(error);
          }
        }
        newDocLines = JSON.stringify(docLines);
        if (newDocLines.indexOf("\u0000") !== -1) {
          error = new Error("null bytes found in doc lines");
          logger.error({
            err: error,
            doc_id: doc_id,
            newDocLines: newDocLines
          }, error.message);
          return callback(error);
        }
        newHash = RedisManager._computeHash(newDocLines);
        opVersions = appliedOps.map(function(op) {
          return op != null ? op.v : void 0;
        });
        logger.log({
          doc_id: doc_id,
          version: newVersion,
          hash: newHash,
          op_versions: opVersions
        }, "updating doc in redis");
        return RedisManager._serializeRanges(ranges, function(error, ranges) {
          var multi;
          if (error != null) {
            logger.error({
              err: error,
              doc_id: doc_id
            }, error.message);
            return callback(error);
          }
          if ((ranges != null) && ranges.indexOf("\u0000") !== -1) {
            error = new Error("null bytes found in ranges");
            logger.error({
              err: error,
              doc_id: doc_id,
              ranges: ranges
            }, error.message);
            return callback(error);
          }
          multi = rclient.multi();
          multi.set(keys.docLines({
            doc_id: doc_id
          }), newDocLines);
          multi.set(keys.docVersion({
            doc_id: doc_id
          }), newVersion);
          multi.set(keys.docHash({
            doc_id: doc_id
          }), newHash);
          multi.ltrim(keys.docOps({
            doc_id: doc_id
          }), -RedisManager.DOC_OPS_MAX_LENGTH, -1);
          if (ranges != null) {
            multi.set(keys.ranges({
              doc_id: doc_id
            }), ranges);
          } else {
            multi.del(keys.ranges({
              doc_id: doc_id
            }));
          }
          if (jsonOps.length > 0) {
            multi.rpush.apply(multi, [keys.docOps({
              doc_id: doc_id
            })].concat(__slice.call(jsonOps)));
            multi.expire(keys.docOps({
              doc_id: doc_id
            }), RedisManager.DOC_OPS_TTL);
            if (projectHistoryType === "project-history") {
              metrics.inc('history-queue', 1, {
                status: 'skip-track-changes'
              });
              logger.log({
                doc_id: doc_id
              }, "skipping push of uncompressed ops for project using project-history");
            } else {
              metrics.inc('history-queue', 1, {
                status: 'track-changes'
              });
              multi.rpush.apply(multi, [historyKeys.uncompressedHistoryOps({
                doc_id: doc_id
              })].concat(__slice.call(jsonOps)));
            }
            multi.set(keys.unflushedTime({
              doc_id: doc_id
            }), Date.now(), "NX");
            multi.set(keys.lastUpdatedAt({
              doc_id: doc_id
            }), Date.now());
            if (updateMeta != null ? updateMeta.user_id : void 0) {
              multi.set(keys.lastUpdatedBy({
                doc_id: doc_id
              }), updateMeta.user_id);
            } else {
              multi.del(keys.lastUpdatedBy({
                doc_id: doc_id
              }));
            }
          }
          return multi.exec(function(error, result) {
            var docUpdateCount, _ref1, _ref2;
            if (error != null) {
              return callback(error);
            }
            if (projectHistoryType === 'project-history') {
              docUpdateCount = void 0;
            } else {
              docUpdateCount = result[7];
            }
            if (jsonOps.length > 0 && ((_ref1 = Settings.apis) != null ? (_ref2 = _ref1.project_history) != null ? _ref2.enabled : void 0 : void 0)) {
              metrics.inc('history-queue', 1, {
                status: 'project-history'
              });
              return ProjectHistoryRedisManager.queueOps.apply(ProjectHistoryRedisManager, [project_id].concat(__slice.call(jsonOps), [function(error, projectUpdateCount) {
                return callback(null, docUpdateCount, projectUpdateCount);
              }]));
            } else {
              return callback(null, docUpdateCount);
            }
          });
        });
      });
    },
    renameDoc: function(project_id, doc_id, user_id, update, projectHistoryId, callback) {
      if (callback == null) {
        callback = function(error) {};
      }
      return RedisManager.getDoc(project_id, doc_id, function(error, lines, version) {
        if (error != null) {
          return callback(error);
        }
        if ((lines != null) && (version != null)) {
          return rclient.set(keys.pathname({
            doc_id: doc_id
          }), update.newPathname, function(error) {
            if (error != null) {
              return callback(error);
            }
            return ProjectHistoryRedisManager.queueRenameEntity(project_id, projectHistoryId, 'doc', doc_id, user_id, update, callback);
          });
        } else {
          return ProjectHistoryRedisManager.queueRenameEntity(project_id, projectHistoryId, 'doc', doc_id, user_id, update, callback);
        }
      });
    },
    clearUnflushedTime: function(doc_id, callback) {
      if (callback == null) {
        callback = function(error) {};
      }
      return rclient.del(keys.unflushedTime({
        doc_id: doc_id
      }), callback);
    },
    getDocIdsInProject: function(project_id, callback) {
      if (callback == null) {
        callback = function(error, doc_ids) {};
      }
      return rclient.smembers(keys.docsInProject({
        project_id: project_id
      }), callback);
    },
    getDocTimestamps: function(doc_ids, callback) {
      if (callback == null) {
        callback = function(error, result) {};
      }
      return async.mapSeries(doc_ids, function(doc_id, cb) {
        return rclient.get(keys.lastUpdatedAt({
          doc_id: doc_id
        }), cb);
      }, callback);
    },
    queueFlushAndDeleteProject: function(project_id, callback) {
      var SMOOTHING_OFFSET;
      SMOOTHING_OFFSET = Settings.smoothingOffset > 0 ? Math.round(Settings.smoothingOffset * Math.random()) : 0;
      return rclient.zadd(keys.flushAndDeleteQueue(), Date.now() + SMOOTHING_OFFSET, project_id, callback);
    },
    getNextProjectToFlushAndDelete: function(cutoffTime, callback) {
      if (callback == null) {
        callback = function(error, key, timestamp) {};
      }
      return rclient.zrangebyscore(keys.flushAndDeleteQueue(), 0, cutoffTime, "WITHSCORES", "LIMIT", 0, 1, function(err, reply) {
        var multi;
        if (err != null) {
          return callback(err);
        }
        if (!(reply != null ? reply.length : void 0)) {
          return callback();
        }
        multi = rclient.multi();
        multi.zrange(keys.flushAndDeleteQueue(), 0, 0, "WITHSCORES");
        multi.zremrangebyrank(keys.flushAndDeleteQueue(), 0, 0);
        multi.zcard(keys.flushAndDeleteQueue());
        return multi.exec(function(err, reply) {
          var key, queueLength, timestamp, _ref1;
          if (err != null) {
            return callback(err);
          }
          if (!(reply != null ? reply.length : void 0)) {
            return callback();
          }
          _ref1 = reply[0], key = _ref1[0], timestamp = _ref1[1];
          queueLength = reply[2];
          return callback(null, key, timestamp, queueLength);
        });
      });
    },
    _serializeRanges: function(ranges, callback) {
      var jsonRanges;
      if (callback == null) {
        callback = function(error, serializedRanges) {};
      }
      jsonRanges = JSON.stringify(ranges);
      if ((jsonRanges != null) && jsonRanges.length > MAX_RANGES_SIZE) {
        return callback(new Error("ranges are too large"));
      }
      if (jsonRanges === '{}') {
        jsonRanges = null;
      }
      return callback(null, jsonRanges);
    },
    _deserializeRanges: function(ranges) {
      if ((ranges == null) || ranges === "") {
        return {};
      } else {
        return JSON.parse(ranges);
      }
    },
    _computeHash: function(docLines) {
      return crypto.createHash('sha1').update(docLines, 'utf8').digest('hex');
    }
  };

}).call(this);

//# sourceMappingURL=RedisManager.map
